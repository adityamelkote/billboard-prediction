{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94f1c01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cdd0f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1: Obtain top 100 billboard list\n",
    "import billboard\n",
    "chart = billboard.ChartData('hot-100')\n",
    "songs = chart.entries\n",
    "\n",
    "data = []\n",
    "for i, song in enumerate(songs):\n",
    "    data.append({'Rank': i+1, 'Song': song.title, 'Artist': song.artist})\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fa3c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_song(row):\n",
    "    # Step 2: Obtain Lyrics\n",
    "    genius_lyrics_link = get_genius_lyrics_link(row['Song'], row['Artist'])\n",
    "    \n",
    "    # Step 3: Obtain Youtube Link\n",
    "    audio_link = get_youtube_audio_link(row['Song'], row['Artist'])\n",
    "    \n",
    "    # Step 4: Obtain downloaded audio file\n",
    "    download_audio(audio_link, row['Rank'], row['Song'])\n",
    "    \n",
    "    # Step 6: For each link, obtain actual lyrics, clean and featurize\n",
    "    lyrics = get_lyrics(genius_lyrics_link)\n",
    "    \n",
    "    # Step 7: Featurize the lyrics using a pre-trained word2vec model\n",
    "    model = api.load('word2vec-google-news-300')\n",
    "    lyrics = lyrics.lower()\n",
    "    words = lyrics.split()\n",
    "    vectors = []\n",
    "    for word in words:\n",
    "        if word in model:\n",
    "            vector = model[word]\n",
    "            vectors.append(vector)\n",
    "    vectors = np.array(vectors)\n",
    "    \n",
    "    # Step 8: Featurize the audio file and the lyrics for each song\n",
    "    y, sr = librosa.load(f'Audio Files/{row[\"Song\"]}.mp4')\n",
    "    \n",
    "    # Compute time-varying audio features\n",
    "    zcr = librosa.feature.zero_crossing_rate(y)\n",
    "    centroid = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "    bandwidth = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "    contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
    "    rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "    flatness = librosa.feature.spectral_flatness(y=y)\n",
    "    flux = librosa.onset.onset_strength(y=y, sr=sr)\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr)\n",
    "    chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "\n",
    "#     Transpose the feature arrays to get one row per time frame\n",
    "#     zcr = zcr.T\n",
    "#     centroid = centroid.T\n",
    "#     bandwidth = bandwidth.T\n",
    "#     contrast = contrast.T\n",
    "#     rolloff = rolloff.T\n",
    "#     flatness = flatness.T\n",
    "#     flux = flux.T\n",
    "#     mfccs = mfccs.T\n",
    "#     chroma = chroma.T\n",
    "\n",
    "#     Create a pandas DataFrame\n",
    "#     df_features=pd.DataFrame(vectors.mean(axis=0),columns=[f'vectors_{i}' for i in range(vectors.shape[1])])\n",
    "#     df_features['zcr'] = zcr.mean()\n",
    "#     df_features['centroid'] = centroid.mean()\n",
    "#     df_features['bandwidth'] = bandwidth.mean()\n",
    "#     df_features[[f'contrast_{i}' for i in range(contrast.shape[1])]] = contrast.mean(axis=1)\n",
    "#     df_features['rolloff'] = rolloff.mean()\n",
    "#     df_features['flatness'] = flatness.mean()\n",
    "#     df_features['flux'] = flux.mean()\n",
    "#     df_features[[f'mfcc_{i}' for i in range(mfccs.shape[1])]] = mfccs.mean(axis=1)\n",
    "#     df_features[[f'chroma_{i}' for i in range(chroma.shape[1])]] = chroma.mean(axis=1)\n",
    "\n",
    "     os.remove(f'Audio Files/{row[\"Song\"]}.mp4')\n",
    "    \n",
    "#     return df_features\n",
    "\n",
    "df_processed_songs_list=[]\n",
    "for i,row in df.iterrows():\n",
    "      df_processed_songs_list.append(process_song(row))\n",
    "df_processed_songs=pd.concat(df_processed_songs_list,axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "869a573d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2: \n",
    "#Obtain Lyrics\n",
    "from googlesearch import search\n",
    "import time\n",
    "def get_genius_lyrics_link(song, artist):\n",
    "    query = f'{song} {artist} genius lyrics'\n",
    "    for url in search(query, num_results=1):\n",
    "        sleep_time = random.uniform(.5,2)  \n",
    "        time.sleep(sleep_time)\n",
    "        return url\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e69a13b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3: Obtain Youtube Link\n",
    "from duckduckgo_search import DDGS\n",
    "from itertools import islice\n",
    "\n",
    "\n",
    "def get_youtube_audio_link(song, artist):\n",
    "    with DDGS() as ddgs:\n",
    "        query = f'{song} {artist} youtube audio'\n",
    "        sleep_time = random.uniform(2, 10)  \n",
    "        ddgs_gen = ddgs.text(query, backend=\"lite\")\n",
    "        for r in ddgs_gen:\n",
    "            sleep_time = random.uniform(.5,2)  \n",
    "            time.sleep(sleep_time)  # Sleep for the specified amount of time\n",
    "            if 'youtube' in r['href'] and 'watch' in r['href']:\n",
    "                return r['href']\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955cbf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 4: Obtain downloaded audio file\n",
    "from pytube import YouTube\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "\n",
    "from pytube import YouTube\n",
    "from pydub import AudioSegment\n",
    "\n",
    "def download_audio(url, rank, song):\n",
    "    try:\n",
    "        yt = YouTube(url)\n",
    "        stream = yt.streams.filter(only_audio=True).first()\n",
    "        filename = f'{song}'\n",
    "        stream.download(output_path='Audio Files', filename=filename)\n",
    "        \n",
    "        # Convert the downloaded file from mp4 to mp3\n",
    "        audio = AudioSegment.from_file(f'Audio Files/{filename}.mp4', format=\"mp4\")\n",
    "        audio.export(f'Audio Files/{filename}.mp3', format=\"mp3\")\n",
    "    except Exception as e:\n",
    "        print(f'Error downloading audio for rank {rank}: {e}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1d4616f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 6: For each link, obtain actual lyrics, clean and featurize\n",
    "\n",
    "import time\n",
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_lyrics(url):\n",
    "    # Set the URL of the song\n",
    "    url = url\n",
    "\n",
    "    # Send an HTTP GET request\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Parse the HTML response\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Find the lyrics element\n",
    "        lyrics_element = soup.find('div', class_='Lyrics__Container-sc-1ynbvzw-5')\n",
    "\n",
    "        # Get the lyrics text\n",
    "        lyrics = lyrics_element.get_text(separator='\\n')\n",
    "        import re\n",
    "        lyrics = re.sub(r'\\[[^]]*\\]', ' ', lyrics)\n",
    "        \n",
    "        # Return the lyrics\n",
    "        \n",
    "        return lyrics\n",
    "    else:\n",
    "        print(f'Failed to retrieve data: {response.status_code}')\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec964ab9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dbf972",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e69a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Train machine learning model\n",
    "import tensorflow as tf\n",
    "# Convert the DataFrame to a 3D numpy array\n",
    "audio_features = df.to_numpy().reshape(-1, df.shape[0], df.shape[1])\n",
    "\n",
    "# Expand the word2vec vectors to have the same number of time steps\n",
    "vectors_expanded = np.repeat(vectors[np.newaxis, :, :], audio_features.shape[1], axis=0)\n",
    "\n",
    "# Transpose the first two axes of audio_features\n",
    "audio_features = np.transpose(audio_features, (1, 0, 2))\n",
    "\n",
    "# Expand the second dimension of audio_features to match vectors_expanded\n",
    "audio_features = np.repeat(audio_features, vectors_expanded.shape[1], axis=1)\n",
    "\n",
    "# Concatenate the word2vec vectors and audio features\n",
    "X = np.concatenate([vectors_expanded, audio_features], axis=2)\n",
    "\n",
    "# Define the input shape\n",
    "input_shape = (X.shape[1], X.shape[2])\n",
    "\n",
    "# Create a sequential model\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "# Add an LSTM layer with 16 units\n",
    "model.add(tf.keras.layers.LSTM(16, input_shape=input_shape))\n",
    "\n",
    "# Add a dropout layer with a rate of 0.5\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "# Add a dense output layer with sigmoid activation\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model with binary cross-entropy loss and the Adam optimizer\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Assume `labels` is a numpy array containing the corresponding labels\n",
    "\n",
    "# Train the model on the concatenated features and labels\n",
    "history = model.fit(X, labels, epochs=10, validation_split=0.2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
